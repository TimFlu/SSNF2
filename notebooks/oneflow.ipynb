{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedf88f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2, expon, weibull_min\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import nflows\n",
    "from nflows import flows, transforms\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import ConditionalDiagonalNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.nn.nets import ResidualNet\n",
    "\n",
    "np.random.seed(100)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb4ad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a69c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe,\n",
    "        context_variables,\n",
    "        target_variables,\n",
    "        device=None,\n",
    "        rows=None,\n",
    "    ):\n",
    "        self.context_variables = context_variables\n",
    "        self.target_variables = target_variables\n",
    "        self.all_variables = context_variables + target_variables\n",
    "        data = dataframe\n",
    "        if rows is not None:\n",
    "            data = data.iloc[:rows]\n",
    "        self.target = data[target_variables].values\n",
    "        self.context = data[context_variables].values\n",
    "        self.weights = data[['weight']].values\n",
    "        if device is not None:\n",
    "            self.target = torch.tensor(self.target, dtype=torch.float32).to(device)\n",
    "            self.context = torch.tensor(self.context, dtype=torch.float32).to(device)\n",
    "            self.weights = torch.tensor(self.weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.context) == len(self.target)\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.context[idx], self.target[idx], self.weights[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b45b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"./samples\"\n",
    "df = pd.read_parquet(os.path.join(input_dir, \"train.parquet\"))\n",
    "df_target = pd.read_parquet(os.path.join(input_dir, \"train_target.parquet\"))\n",
    "df_test = pd.read_parquet(os.path.join(input_dir, \"test.parquet\"))\n",
    "df_target_test = pd.read_parquet(os.path.join(input_dir, \"test_target.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3562d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lab'] = 1\n",
    "df_test['lab'] = 1\n",
    "df_target['lab'] = 0\n",
    "df_target_test['lab'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf55916",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = pd.concat([df, df_target])\n",
    "new_df_train = new_df_train.reset_index(drop=True)\n",
    "new_df_train = new_df_train.sample(frac=1).reset_index(drop=True)\n",
    "new_df_test = pd.concat([df_test, df_target_test])\n",
    "new_df_test = new_df_test.reset_index(drop=True)\n",
    "new_df_test = new_df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4b7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800000 1200000\n"
     ]
    }
   ],
   "source": [
    "context_vars = ['a', 'b', 'lab']\n",
    "input_vars = ['x', 'y']\n",
    "rows = 200000\n",
    "rows_test = 100000\n",
    "batch_size = 1000\n",
    "print(len(new_df_train), len(new_df_test))\n",
    "\n",
    "new_dataset_train = MyDataset(new_df_train, context_vars, input_vars, device=device, rows=rows)\n",
    "new_loader_train = DataLoader(new_dataset_train, batch_size=batch_size)\n",
    "new_dataset_test = MyDataset(new_df_test, context_vars, input_vars, device=device, rows=rows)\n",
    "new_loader_test = DataLoader(new_dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c0b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(flow, df_mc, df_data):\n",
    "    abl = torch.tensor(df_mc[['a', 'b', 'lab']].values, dtype=torch.float32).to(device)\n",
    "    xy_uncorr = torch.tensor(df_mc[['x', 'y']].values, dtype=torch.float32).to(device)\n",
    "    xy_uncorr_latent = flow._transform(xy_uncorr, abl)[0]\n",
    "    x_uncorr_latent, y_uncorr_latent = xy_uncorr_latent[:, 0].detach().cpu().numpy(), xy_uncorr_latent[:, 1].detach().cpu().numpy()\n",
    "    x_uncorr, y_uncorr = xy_uncorr[:, 0].detach().cpu().numpy(), xy_uncorr[:, 1].detach().cpu().numpy()\n",
    "    #weights = torch.tensor(df_mc['weight'].values).to(device)\n",
    "    \n",
    "    # second part of transformation\n",
    "    zeros = torch.zeros(xy_uncorr_latent.shape[0], 1).to(device)\n",
    "    ab = torch.tensor(df_mc[['a', 'b']].values, dtype=torch.float32).to(device)\n",
    "    abl = torch.cat((ab, zeros), axis=1)\n",
    "    xy_corr = flow._transform.inverse(xy_uncorr_latent, abl)[0]\n",
    "    x_corr, y_corr = xy_corr[:, 0].detach().cpu().numpy(), xy_corr[:, 1].detach().cpu().numpy()\n",
    "    \n",
    "    # get from data\n",
    "    x_data, y_data = df_data[['x']].values, df_data[['y']].values\n",
    "    \n",
    "    #weights = weights.detach().cpu().values\n",
    "    weights = df_mc['weight'].values\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\n",
    "    ax1.hist(x_uncorr_latent, bins=100, density=True, label='latent', weights=weights)\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.legend()\n",
    "    ax2.hist(y_uncorr_latent, bins=100, density=True, label='latent', weights=weights)\n",
    "    ax2.set_xlabel('y')\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\n",
    "    ax1.hist(x_uncorr, bins=100, density=True, label='uncorr', weights=weights)\n",
    "    ax1.hist(x_data, bins=100, density=True, label='data')\n",
    "    ax1.hist(x_corr, bins=100, density=True, label='corr', alpha=0.5, weights=weights)\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.legend()\n",
    "    ax2.hist(y_uncorr, bins=100, density=True, label='uncorr', weights=weights)\n",
    "    ax2.hist(y_data, bins=100, density=True, label='data')\n",
    "    ax2.hist(y_corr, bins=100, density=True, label='corr', alpha=0.5, weights=weights)\n",
    "    ax2.set_xlabel('y')\n",
    "    ax2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8311b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninput = 2\n",
    "ncontext = 3\n",
    "\n",
    "epochs = 30\n",
    "plot_every = 10\n",
    "\n",
    "def spline_inn(\n",
    "    inp_dim,\n",
    "    nodes=128,\n",
    "    num_blocks=2,\n",
    "    num_stack=3,\n",
    "    tail_bound=3.5,\n",
    "    tails=\"linear\",\n",
    "    activation=F.relu,\n",
    "    lu=0,\n",
    "    num_bins=12,\n",
    "    context_features=None,\n",
    "    dropout_probability=0.0,\n",
    "    flow_for_flow=False,\n",
    "):\n",
    "    transform_list = []\n",
    "    for i in range(num_stack):\n",
    "        transform_list += [\n",
    "            transforms.MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "                inp_dim,\n",
    "                nodes,\n",
    "                num_blocks=num_blocks,\n",
    "                tail_bound=tail_bound,\n",
    "                num_bins=num_bins,\n",
    "                tails=tails,\n",
    "                activation=activation,\n",
    "                dropout_probability=dropout_probability,\n",
    "                context_features=context_features,\n",
    "            )\n",
    "        ]\n",
    "        if lu:\n",
    "            transform_list += [transforms.LULinear(inp_dim)]\n",
    "        else:\n",
    "            transform_list += [transforms.ReversePermutation(inp_dim)]\n",
    "\n",
    "    if not (flow_for_flow and (num_stack % 2 == 0)):\n",
    "        # If the above conditions are satisfied then you want to permute back to the original ordering such that the\n",
    "        # output features line up with their original ordering.\n",
    "        transform_list = transform_list[:-1]\n",
    "\n",
    "    return transforms.CompositeTransform(transform_list)\n",
    "\n",
    "def get_conditional_base_flow(\n",
    "    input_dim,\n",
    "    context_dim,\n",
    "    nstack,\n",
    "    nnodes,\n",
    "    nblocks,\n",
    "    tail_bound,\n",
    "    nbins,\n",
    "    activation,\n",
    "    dropout_probability,\n",
    "):\n",
    "    flow = Flow(\n",
    "        spline_inn(\n",
    "            input_dim,\n",
    "            nodes=nnodes,\n",
    "            num_blocks=nblocks,\n",
    "            num_stack=nstack,\n",
    "            tail_bound=tail_bound,\n",
    "            activation=getattr(F, activation),\n",
    "            dropout_probability=dropout_probability,\n",
    "            num_bins=nbins,\n",
    "            context_features=context_dim,\n",
    "        ),\n",
    "        ConditionalDiagonalNormal(\n",
    "            shape=[input_dim], context_encoder=nn.Linear(context_dim, 2 * input_dim)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return flow\n",
    "\n",
    "def make_flow_and_train(loader, test_loader, df_test):\n",
    "    flow = get_conditional_base_flow(\n",
    "        input_dim=ninput,\n",
    "        context_dim=ncontext,\n",
    "        nstack=3,\n",
    "        nnodes=6,\n",
    "        nblocks=4,\n",
    "        tail_bound=1.0,\n",
    "        nbins=10,\n",
    "        activation=\"relu\",\n",
    "        dropout_probability=0.1,\n",
    "    )\n",
    "    flow = flow.to(device)\n",
    "    optimizer = optim.Adam(flow.parameters())\n",
    "\n",
    "    train_history, test_history = [], []\n",
    "    for epoch in range(epochs + 1):\n",
    "        print(epoch)\n",
    "        train_losses, test_losses = [], []\n",
    "\n",
    "        # train\n",
    "        for abl, xy, weights in loader:\n",
    "            loss = -flow.log_prob(inputs=xy, context=abl) * weights\n",
    "            loss = loss.mean()\n",
    "            train_losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_train_loss = np.mean(train_losses)\n",
    "        train_history.append(epoch_train_loss)\n",
    "\n",
    "        # test\n",
    "        print('testing')\n",
    "        for abl, xy, weights in test_loader:\n",
    "            with torch.no_grad():\n",
    "                loss = -flow.log_prob(inputs=xy, context=abl) * weights\n",
    "                loss = loss.mean()\n",
    "                test_losses.append(loss.item())\n",
    "        \n",
    "        epoch_test_loss = np.mean(test_losses)\n",
    "        test_history.append(epoch_test_loss)\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            print(\"plotting\")\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "            a, b, l, x, y = df_test['a'].values, df_test['b'].values, df_test['lab'], df_test['x'].values, df_test['y'].values\n",
    "            xy_sample = flow.sample(1, context=torch.tensor(df_test[['a', 'b', 'lab']].values, dtype=torch.float32).to(device)).reshape(-1, ninput)\n",
    "            x_sample = xy_sample[:, 0].detach().cpu().numpy()\n",
    "            y_sample = xy_sample[:, 1].detach().cpu().numpy()\n",
    "            #x_min = min(x.min(), x_sample.min())\n",
    "            #x_max = max(x.max(), x_sample.max())\n",
    "            x_min = 0\n",
    "            x_max = 1\n",
    "            ax1.hist(x, bins=100, range=(x_min, x_max), density=True, alpha=0.5, label='sample');\n",
    "            ax1.hist(x_sample, bins=100, range=(x_min, x_max), density=True, alpha=0.5, label='flow');\n",
    "            ax1.set_xlabel('x')\n",
    "            #y_min = min(y.min(), y_sample.min())\n",
    "            #y_max = max(y.max(), y_sample.max())\n",
    "            y_min = 0\n",
    "            y_max = 1\n",
    "            ax1.legend()\n",
    "            ax2.hist(y, bins=100, range=(y_min, y_max), density=True, alpha=0.5, label='sample');\n",
    "            ax2.hist(y_sample, bins=100, range=(y_min, y_max), density=True, alpha=0.5, label='flow');\n",
    "            ax2.set_xlabel('y')\n",
    "            ax2.legend()\n",
    "            # plot loss\n",
    "            ax3.plot(train_history, label='train')\n",
    "            ax3.plot(test_history, label='test')\n",
    "            ax3.legend()\n",
    "            plt.show()\n",
    "            apply(flow, df_test, df_target_test)\n",
    "    \n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae512460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "testing\n",
      "plotting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 14.75 GiB total capacity; 13.54 GiB already allocated; 78.81 MiB free; 13.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2702/2769949537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_flow_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_df_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2702/2509917213.py\u001b[0m in \u001b[0;36mmake_flow_and_train\u001b[0;34m(loader, test_loader, df_test)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0max3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2702/3802725952.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(flow, df_mc, df_data)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mabl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mxy_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_uncorr_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mx_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy_corr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy_corr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mfuncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cascade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36m_cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_logabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nflows/transforms/autoregressive.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mautoregressive_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoregressive_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             outputs, logabsdet = self._elementwise_inverse(\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoregressive_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nflows/transforms/autoregressive.py\u001b[0m in \u001b[0;36m_elementwise_inverse\u001b[0;34m(self, inputs, autoregressive_params)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_elementwise_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoregressive_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elementwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoregressive_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nflows/transforms/autoregressive.py\u001b[0m in \u001b[0;36m_elementwise\u001b[0;34m(self, inputs, autoregressive_params, inverse)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         outputs, logabsdet = spline_fn(\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0munnormalized_widths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munnormalized_widths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nflows/transforms/splines/rational_quadratic.py\u001b[0m in \u001b[0;36munconstrained_rational_quadratic_spline\u001b[0;34m(inputs, unnormalized_widths, unnormalized_heights, unnormalized_derivatives, inverse, tails, tail_bound, min_bin_width, min_bin_height, min_derivative)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_interval_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlogabsdet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_interval_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrational_quadratic_spline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_interval_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0munnormalized_widths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munnormalized_widths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_interval_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nflows/transforms/splines/rational_quadratic.py\u001b[0m in \u001b[0;36mrational_quadratic_spline\u001b[0;34m(inputs, unnormalized_widths, unnormalized_heights, unnormalized_derivatives, inverse, left, right, bottom, top, min_bin_width, min_bin_height, min_derivative)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mheights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munnormalized_heights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mheights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_bin_height\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_bin_height\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_bins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mcumheights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mcumheights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumheights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 14.75 GiB total capacity; 13.54 GiB already allocated; 78.81 MiB free; 13.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "flow = make_flow_and_train(new_loader_train, new_loader_test, new_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd2e43",
   "metadata": {},
   "source": [
    "## Apply it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(flow, df_test, df_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a77d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
